{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "import plotly.graph_objs as go ;from plotly import tools ;\n",
    "from plotly.offline import iplot,init_notebook_mode\n",
    "import matplotlib.pyplot as plt\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                            Message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_table(\"smsspamcollection/SMSSpamCollection\",names=[\"Target\",\"Message\"])\n",
    "df['Message']=df['Message'].str.decode(\"ascii\",\"ignore\")\n",
    "df['Message']=df['Message'].str.encode(\"ascii\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=df.sample(frac=0.8,random_state=0)\n",
    "test=df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process the message, lower case and punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_message(message):\n",
    "    return [x.lower().translate( None,string.punctuation) for x in message.split()] #Return list of processed words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Bag of Words that counts occurances of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_bag={}\n",
    "word_bag['Spam']=Counter(reduce(lambda x,y: x+y,train[train['Target']=='spam']['Message'].apply(process_message)))\n",
    "word_bag['Ham']=Counter(reduce(lambda x,y: x+y,train[train['Target']!='spam']['Message'].apply(process_message)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the probability P(xi|Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_prob(word,target,alpha):\n",
    "    prob_word = word_bag[target][word] if word in word_bag[target] else 0\n",
    "    \n",
    "    return (float)(prob_word + alpha)/(len(word_bag[target])+20000*alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiy the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifiy(message,alpha):\n",
    "    \n",
    "    message = process_message(message) #process message\n",
    "    \n",
    "    Total=(float)(len(word_bag['Spam'])+len(word_bag['Ham'])) #total number of words in bag\n",
    "    \n",
    "    #P(w1)*P(w2)*P(w3)...P(w.n)\n",
    "    Normalizer=np.product([(word_bag['Spam'][word]+word_bag['Ham'][word])/Total for word in message]) \n",
    "    \n",
    "    #P(x1|Y=spam)*P(x2|Y=spam)*P(x3|Y=spam)...P(xn|Y=spam)\n",
    "    Product_SpamWords_Probs=np.product([word_prob(word,'Spam',alpha) for word in message])\n",
    "    \n",
    "    #P(x1|Y=ham)*P(x2|Y=ham)*P(x3|Y=ham)...P(xn|Y=ham)\n",
    "    Product_HamWords_Probs=np.product([word_prob(word,'Ham',alpha) for word in message])\n",
    "    \n",
    "    #P(Y=spam)\n",
    "    Spam_Prob = len(word_bag['Spam'])/Total\n",
    "    \n",
    "    #P(Y=ham)\n",
    "    Ham_Prob = 1 - Spam_Prob\n",
    "    \n",
    "    #P(M=spam) = ( (x1|Y=spam)*P(x2|Y=spam)*P(x3|Y=spam)...P(xn|Y=spam) * P(Y=spam) ) / P(w1)*P(w2)*P(w3)...P(w.n)\n",
    "    message_spam_prob = (Product_SpamWords_Probs * Spam_Prob)/Normalizer\n",
    "    \n",
    "    #P(M=ham) = ( P(x1|Y=ham)*P(x2|Y=ham)*P(x3|Y=ham)...P(xn|Y=ham) * #P(Y=ham) ) / P(w1)*P(w2)*P(w3)...P(w.n)\n",
    "    message_ham_prob = (Product_HamWords_Probs * Ham_Prob)/Normalizer\n",
    "    \n",
    "    return \"spam\" if message_spam_prob > message_ham_prob else \"ham\" #Return the class of the greater probability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifier_performance(data):\n",
    "    \n",
    "    measure={}\n",
    "    Positives = data[data['Predict']=='spam']\n",
    "    Negatives = data[data['Predict']!='spam']\n",
    "    \n",
    "    measure['True_Positives'] = (Positives['Target'] == Positives['Predict']).sum()\n",
    "    measure['False_Positives'] = (Positives['Target'] != Positives['Predict']).sum()\n",
    "    measure['True_Negatives'] = (Negatives['Target'] == Negatives['Predict']).sum()\n",
    "    measure['False_Negatives'] = (Negatives['Target'] != Negatives['Predict']).sum()\n",
    "    \n",
    "    measure['Precision'] = float(measure['True_Positives'])/(measure['True_Positives']+measure['False_Positives'])\n",
    "    measure['Recall'] = float(measure['True_Positives'])/(measure['True_Positives']+measure['False_Negatives']) \n",
    "    measure['F_Score'] = 2 * (measure['Precision']*measure['Recall']/(measure['Precision'] + measure['Recall']))\n",
    "    measure['Accuracy'] = (data['Target']==data['Predict']).sum()/float(len(data))\n",
    "    \n",
    "    return measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the test data using our Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>Im going to try for 2 months ha ha only joking</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup... Ok i go home look at the timings then i...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>spam</td>\n",
       "      <td>Congrats! 1 year special cinema pass for 2 is ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ham</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ham</td>\n",
       "      <td>Its a part of checking IQ</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message Predict\n",
       "0     ham  Go until jurong point, crazy.. Available only ...     ham\n",
       "7     ham  As per your request 'Melle Melle (Oru Minnamin...     ham\n",
       "21    ham     Im going to try for 2 months ha ha only joking     ham\n",
       "24    ham  Ffffffffff. Alright no way I can meet up with ...     ham\n",
       "25    ham  Just forced myself to eat a slice. I'm really ...     ham\n",
       "28    ham  I'm back &amp; we're packing the car now, I'll...     ham\n",
       "35    ham  Yup... Ok i go home look at the timings then i...     ham\n",
       "56   spam  Congrats! 1 year special cinema pass for 2 is ...    spam\n",
       "60    ham  Your gonna have to pick up a $1 burger for you...     ham\n",
       "62    ham                          Its a part of checking IQ     ham"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Predict']=test['Message'].apply(lambda x: classifiy(x,0.1))\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix and Accuracy, Precision, Recall and F-Score Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+\n",
      "|          |   Positive |   Negative |\n",
      "+==========+============+============+\n",
      "| Positive |         55 |          1 |\n",
      "+----------+------------+------------+\n",
      "| Negative |         84 |        974 |\n",
      "+----------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "measures = classifier_performance(test)\n",
    "\n",
    "print tabulate([[\"Positive\",measures[\"True_Positives\"], measures[\"False_Positives\"]],\n",
    "                 [\"Negative\",measures[\"False_Negatives\"], measures[\"True_Negatives\"]]],\n",
    "               [\"Positive\", \"Negative\"], tablefmt=\"grid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+----------+-----------+\n",
      "| Accuracy   | Precision   | Recall   | F_Score   |\n",
      "+============+=============+==========+===========+\n",
      "| 92.0%      | 98.0%       | 40.0%    | 56.0%     |\n",
      "+------------+-------------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "print tabulate([[str(round(measures[\"Accuracy\"],2)*100)+\"%\",\n",
    "                 str(round(measures[\"Precision\"],2)*100)+\"%\",\n",
    "                 str(round(measures[\"Recall\"],2)*100)+\"%\",\n",
    "                 str(round(measures[\"F_Score\"],2)*100)+\"%\"]],\n",
    "               [\"Accuracy\",\"Precision\",\"Recall\",\"F_Score\"],tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Accuracy & F-Score using different values of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "F-Score",
         "type": "scatter",
         "x": [
          0.03125,
          0.0625,
          0.125,
          0.25,
          0.5,
          1
         ],
         "y": [
          0.9833333333333334,
          0.9781879194630873,
          0.9694915254237287,
          0.9562231759656653,
          0.9113697403760072,
          0.8484848484848484
         ]
        },
        {
         "name": "Accuracy",
         "type": "scatter",
         "x": [
          0.03125,
          0.0625,
          0.125,
          0.25,
          0.5,
          1
         ],
         "y": [
          0.9955136832660386,
          0.9941677882458502,
          0.9919246298788694,
          0.9885598923283984,
          0.977792732166891,
          0.9641094661283086
         ]
        }
       ],
       "layout": {
        "title": "Train Data Performance",
        "xaxis": {
         "title": "Alphas",
         "type": "category"
        },
        "yaxis": {
         "range": [
          0.7,
          1
         ],
         "tickformat": ".2%"
        }
       }
      },
      "text/html": [
       "<div id=\"612bbdaf-751d-4809-a70d-f96cc4f14c73\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"612bbdaf-751d-4809-a70d-f96cc4f14c73\", [{\"y\": [0.9833333333333334, 0.9781879194630873, 0.9694915254237287, 0.9562231759656653, 0.9113697403760072, 0.8484848484848484], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"F-Score\"}, {\"y\": [0.9955136832660386, 0.9941677882458502, 0.9919246298788694, 0.9885598923283984, 0.977792732166891, 0.9641094661283086], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"Accuracy\"}], {\"yaxis\": {\"range\": [0.7, 1], \"tickformat\": \".2%\"}, \"xaxis\": {\"type\": \"category\", \"title\": \"Alphas\"}, \"title\": \"Train Data Performance\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"612bbdaf-751d-4809-a70d-f96cc4f14c73\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"612bbdaf-751d-4809-a70d-f96cc4f14c73\", [{\"y\": [0.9833333333333334, 0.9781879194630873, 0.9694915254237287, 0.9562231759656653, 0.9113697403760072, 0.8484848484848484], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"F-Score\"}, {\"y\": [0.9955136832660386, 0.9941677882458502, 0.9919246298788694, 0.9885598923283984, 0.977792732166891, 0.9641094661283086], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"Accuracy\"}], {\"yaxis\": {\"range\": [0.7, 1], \"tickformat\": \".2%\"}, \"xaxis\": {\"type\": \"category\", \"title\": \"Alphas\"}, \"title\": \"Train Data Performance\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas=[2**i for i in range(-5,1)] #Values of Alpha\n",
    "\n",
    "\n",
    "\n",
    "Train_Fscores=[]; Test_Fscores=[];  Train_Accuracy=[]; Test_Accuracy=[];\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    test['Predict']=test['Message'].apply(lambda x: classifiy(x,alpha)) # Classifiy the Test Data \n",
    "    \n",
    "    measures = classifier_performance(test) # Get the performance measures\n",
    "    \n",
    "    #Append Accuracy and Fscore to Test List\n",
    "    Test_Fscores.append(measures['F_Score'])\n",
    "    Test_Accuracy.append(measures['Accuracy'])\n",
    "    \n",
    "    #Do the same for Train Data\n",
    "    train['Predict']=train['Message'].apply(lambda x: classifiy(x,alpha))\n",
    "    \n",
    "    measures = classifier_performance(train)\n",
    "    \n",
    "    Train_Fscores.append(measures['F_Score'])\n",
    "    Train_Accuracy.append(measures['Accuracy'])\n",
    "    \n",
    "\n",
    "\n",
    "trace1 = go.Scatter( x = alphas, y = Train_Fscores, name = \"F-Score\") #Line Plot for F-Score in Train Data\n",
    "\n",
    "trace2 = go.Scatter( x = alphas, y = Train_Accuracy, name = \"Accuracy\") #Line Plot for Accuracy in Train Data\n",
    "\n",
    "# Customize Layout\n",
    "layout = go.Layout( title=\"Train Data Performance\",\n",
    "                    xaxis=dict( title=\"Alphas\", type= \"category\"),\n",
    "                    yaxis=dict(range=[0.7,1],tickformat=\".2%\"))\n",
    "\n",
    "fig=dict(data=[trace1,trace2],layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "F-Score",
         "type": "scatter",
         "x": [
          0.03125,
          0.0625,
          0.125,
          0.25,
          0.5,
          1
         ],
         "y": [
          0.5641025641025641,
          0.5641025641025641,
          0.5641025641025641,
          0.5567010309278351,
          0.5340314136125655,
          0.4782608695652174
         ]
        },
        {
         "name": "Accuracy",
         "type": "scatter",
         "x": [
          0.03125,
          0.0625,
          0.125,
          0.25,
          0.5,
          1
         ],
         "y": [
          0.9236983842010772,
          0.9236983842010772,
          0.9236983842010772,
          0.9228007181328546,
          0.9201077199281867,
          0.9138240574506283
         ]
        }
       ],
       "layout": {
        "title": "Test Data Performance",
        "xaxis": {
         "title": "Alphas",
         "type": "category"
        },
        "yaxis": {
         "range": [
          0.3,
          1
         ],
         "tickformat": ".2%"
        }
       }
      },
      "text/html": [
       "<div id=\"2d00ddb9-4dbf-47a6-a541-1154bbf89b16\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2d00ddb9-4dbf-47a6-a541-1154bbf89b16\", [{\"y\": [0.5641025641025641, 0.5641025641025641, 0.5641025641025641, 0.5567010309278351, 0.5340314136125655, 0.4782608695652174], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"F-Score\"}, {\"y\": [0.9236983842010772, 0.9236983842010772, 0.9236983842010772, 0.9228007181328546, 0.9201077199281867, 0.9138240574506283], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"Accuracy\"}], {\"yaxis\": {\"range\": [0.3, 1], \"tickformat\": \".2%\"}, \"xaxis\": {\"type\": \"category\", \"title\": \"Alphas\"}, \"title\": \"Test Data Performance\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2d00ddb9-4dbf-47a6-a541-1154bbf89b16\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2d00ddb9-4dbf-47a6-a541-1154bbf89b16\", [{\"y\": [0.5641025641025641, 0.5641025641025641, 0.5641025641025641, 0.5567010309278351, 0.5340314136125655, 0.4782608695652174], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"F-Score\"}, {\"y\": [0.9236983842010772, 0.9236983842010772, 0.9236983842010772, 0.9228007181328546, 0.9201077199281867, 0.9138240574506283], \"x\": [0.03125, 0.0625, 0.125, 0.25, 0.5, 1], \"type\": \"scatter\", \"name\": \"Accuracy\"}], {\"yaxis\": {\"range\": [0.3, 1], \"tickformat\": \".2%\"}, \"xaxis\": {\"type\": \"category\", \"title\": \"Alphas\"}, \"title\": \"Test Data Performance\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace1 = go.Scatter( x = alphas, y = Test_Fscores, name = \"F-Score\") #Line Plot for F-Score in Test Data\n",
    "\n",
    "trace2 = go.Scatter( x = alphas, y = Test_Accuracy, name = \"Accuracy\") #Line Plot for Accuracy in Test Data\n",
    "\n",
    "# Customize Layout\n",
    "layout = go.Layout( title=\"Test Data Performance\",\n",
    "                    xaxis=dict( title=\"Alphas\", type= \"category\"),\n",
    "                    yaxis=dict(range=[0.3,1],tickformat=\".2%\"))\n",
    "\n",
    "fig=dict(data=[trace1,trace2],layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
